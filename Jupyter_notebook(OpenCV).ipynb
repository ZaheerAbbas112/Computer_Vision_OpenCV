{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision (OpenCV)\n",
    "## 1- Reading and displying an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "cv.imshow(\"First Image\", img)\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-  Resizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img1 = cv.resize(img, (800,600))\n",
    "cv.imshow(\"First Image\", img)\n",
    "cv.imshow(\"Second Image\", img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Grayscale Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from cv2 import cvtColor\n",
    "\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img = cv.resize(img, (800,600))\n",
    "\n",
    "# conversion\n",
    "gray_img = cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# display code\n",
    "cv.imshow(\"First Image\", img)\n",
    "cv.imshow(\"Gray Image\", gray_img)\n",
    "\n",
    "# delay code\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Image into Black & White image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from cv2 import cvtColor\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img1 = cv.resize(img, (300,200))\n",
    "gray = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "(thresh, binary) = cv.threshold(gray, 127,255, cv.THRESH_BINARY)\n",
    "cv.imshow('original', img1)\n",
    "cv.imshow('gray', gray)\n",
    "cv.imshow('Black and White', binary)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Saving an image or Writing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from cv2 import imshow\n",
    "from cv2 import imwrite\n",
    "img = cv.imread(\"resources/image.jpg\")\n",
    "img1 = cv.resize(img, (300,200))\n",
    "gray = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "(thresh, binary) = cv.threshold(gray, 127,255, cv.THRESH_BINARY)\n",
    "\n",
    "# resize the binary image\n",
    "binary = cv.resize(binary, (100,300))\n",
    "\n",
    "imwrite('resources/image_gray.png', gray)\n",
    "imwrite('resources/image_bw.png', binary)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-  Reading a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('resources/video.mkv')\n",
    "\n",
    "# indicator\n",
    "if (cap.isOpened() == False):\n",
    "    print('error in reading video')\n",
    "\n",
    "# reading and playing\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv.imshow('Video', frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Converting video to gray or black and white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('resources/video.mkv')\n",
    "\n",
    "while (True):\n",
    "    (ret, frame) = cap.read()\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    (thresh, binary) = cv.threshold(grayframe, 127,255, cv.THRESH_BINARY)\n",
    "    # to show in player\n",
    "    if ret == True:\n",
    "        cv.imshow('Video', binary)\n",
    "        # to quit with 'q' key\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8- Converting video to gray or black and white, and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('resources/video.mkv')\n",
    "\n",
    "# writing format, codec, video writer object, and file output\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter(\"resources/out_video.mkv\", cv.VideoWriter_fourcc('M','J', 'P', 'G'), 10, (frame_width, frame_height), isColor=False)\n",
    "\n",
    "while (True):\n",
    "    (ret, frame) = cap.read()\n",
    "    grayframe = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "   \n",
    "    # to show in player\n",
    "    if ret == True:\n",
    "        out.write(grayframe)\n",
    "        cv.imshow('Video', grayframe)\n",
    "        # to quit with 'q' key\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9- How to capture a webcam inside python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1 import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Step-2 read the frames from camera\n",
    "cap = cv.VideoCapture(0) # for 0 webcam no.1, for 1 webcam no.2\n",
    "\n",
    "# indicator\n",
    "if (cap.isOpened()== False):\n",
    "    print('There is an error')\n",
    "\n",
    "# read untill the end\n",
    "\n",
    "# Step-3 display frame by frame\n",
    "while(cap.isOpened()):\n",
    "    # capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # to display frame\n",
    "        cv.imshow('Frame', frame)\n",
    "        # to quit with 'q' key\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "# Step-4 release or close windows easily\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10- Convert into different shades of Gray and Black and White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Frame\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    (ret, frame) = cap.read()\n",
    "    gray_frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    (thresh, binary) = cv.threshold(gray_frame, 127,255, cv.THRESH_BINARY)\n",
    "\n",
    "    cv.imshow('OriginalCam', frame)\n",
    "    cv.imshow('GrayCam',  gray_frame)\n",
    "    cv.imshow('BinaryCam', binary)\n",
    "    # to quit with 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11- Writing videos from cam (camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# writing format, codec, video writer object, and file output\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter(\"resources/cam_video.mkv\", cv.VideoWriter_fourcc('M','J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "while (True):\n",
    "    (ret, frame) = cap.read()\n",
    "\n",
    "    # to show in player\n",
    "    if ret == True:\n",
    "        out.write(frame)\n",
    "        cv.imshow('Video', frame)\n",
    "        # to quit with 'q' key\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12- Setting of camera or video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "cap = cv.VideoCapture(0)\n",
    "cap.set(10, 50) # 10 is the key to set brightness\n",
    "cap.set(3, 640) # width key 3\n",
    "cap.set(4, 480) # height key 4\n",
    "\n",
    "\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv.imshow(\"frame\", frame)\n",
    "        if cv.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13- Basic functions or manipulator in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import resize\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img = cv.imread('resources/image.jpg')\n",
    "img = cv.resize(img, (500,400))\n",
    "\n",
    "# resize\n",
    "resize_img = cv.resize(img, (500,400))\n",
    "\n",
    "# gray\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "# blurred image\n",
    "blurr_img = cv.GaussianBlur(img, (7,7), 0)\n",
    "\n",
    "# edge detection\n",
    "edge_img = cv.Canny(img, 53,53)\n",
    "\n",
    "# thickness of lines\n",
    "mat_kernel = np.ones((3,3), np.uint8)\n",
    "dilated_img = cv.dilate(edge_img, (mat_kernel), (8,8), iterations=1)\n",
    "\n",
    "# make thinner outline\n",
    "ero_img = cv.erode(dilated_img, mat_kernel, iterations=1)\n",
    "\n",
    "# cropping (we will use numpy library not open cv)\n",
    "print(\"The size of my image is:\", img.shape)\n",
    "cropped_img = img[0:350, 0:300] # height,width\n",
    "\n",
    "# cv.imshow('Original', img)\n",
    "# cv.imshow('Resized', resize_img)\n",
    "# cv.imshow('Gray', gray_img)\n",
    "# cv.imshow('Blurr', blurr_img)\n",
    "# cv.imshow('Edge', edge_img)\n",
    "# cv.imshow('Dilated', dilated_img)\n",
    "# cv.imshow('Erosion', ero_img)\n",
    "cv.imshow('cropped', cropped_img)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14-  How to draw lines, and shapes in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Draw a canvas, 0 is for black, 1 is for white\n",
    "img = np.zeros((600,600)) # black\n",
    "img1 = np.ones((600,600))  # white\n",
    "\n",
    "# print size\n",
    "print(\"The size of our canvas is:\", img.shape)\n",
    "# print(img)\n",
    " # adding colors to the canvas\n",
    "colored_img = np.zeros((600,600,3), np.uint8) # color channel addition\n",
    "\n",
    "colored_img[:] = 255,0,255 # color complete image (color key:255,0,255)\n",
    "colored_img[300:500, 100:500] = 255,0,190 # part of image to be colored\n",
    "\n",
    "# adding line\n",
    "cv.line(colored_img,(0,0),(colored_img.shape[0],colored_img.shape[1] ), (255,0,0), 3) # croosed line\n",
    "cv.line(colored_img,(100,100),(300,300), (255,255,50), 3) # part line\n",
    "\n",
    "# adding rectangles\n",
    "cv.rectangle(colored_img, (50,100) , (300,400), (300,300,255), 3) # draw\n",
    "cv.rectangle(colored_img, (50,100) , (300,400), (300,300,255), cv.FILLED) # fill\n",
    "\n",
    "# adding circle\n",
    "cv.circle(colored_img, (500,200), 50, (255,100,0), 5) # draw circle\n",
    "cv.circle(colored_img, (500,200), 50, (255,100,0), cv.FILLED) # filled circle\n",
    "\n",
    "# adding text\n",
    "cv.putText(colored_img, \"Python ka chilla with baba Aamar\", (30,50), cv.FONT_HERSHEY_DUPLEX, 1, (255,255,0), 2 )\n",
    "\n",
    "\n",
    "# cv.imshow('Black', img)\n",
    "# cv.imshow('White', img1)\n",
    "cv.imshow('Colored', colored_img)\n",
    "cv.waitKey(0)\n",
    "\n",
    "cv.destroyAllwindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15- Resolution of cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# capture your camera\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# resolution (HD:1280*720)\n",
    "cap.set(3,1280) # 3 for width\n",
    "cap.set(4,720)  # 4 for height\n",
    "\n",
    "def hd_resolution():\n",
    "    cap.set(3,1280)\n",
    "    cap.set(4,720)\n",
    "\n",
    "def sd_resolution():\n",
    " cap.set(3,640)\n",
    " cap.set(4,480)\n",
    "\n",
    "def fhd_resolution():\n",
    " cap.set(3,1920)\n",
    " cap.set(4,1080)\n",
    " \n",
    "# hd_resolution()\n",
    "# sd_resolution()\n",
    "# fhd_resolution()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv.imshow(\"Camera\", frame)\n",
    "        if cv.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16- Saving HD recording of cam steaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# capture your camera\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# resolution (HD:1280*720)\n",
    "cap.set(3,1280) # 3 for width\n",
    "cap.set(4,720)  # 4 for height\n",
    "\n",
    "def hd_resolution():\n",
    "    cap.set(3,1280)\n",
    "    cap.set(4,720)\n",
    "\n",
    "def sd_resolution():\n",
    " cap.set(3,640)\n",
    " cap.set(4,480)\n",
    "\n",
    "def fhd_resolution():\n",
    " cap.set(3,1920)\n",
    " cap.set(4,1080)\n",
    "\n",
    "\n",
    "# hd_resolution()\n",
    "# sd_resolution()\n",
    "# fhd_resolution()\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "out = cv.VideoWriter(\"resources/cam_video.mkv\", cv.VideoWriter_fourcc('M','J', 'P', 'G'), 10, (frame_width, frame_height))\n",
    "\n",
    "while (True):\n",
    "    (ret, frame) = cap.read()\n",
    "    # to show in player\n",
    "    if ret == True:\n",
    "        out.write(frame)\n",
    "        cv.imshow('Video', frame)\n",
    "        # to quit with 'q' key\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17- Joining two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv.imread(\"resources/image.jpg\")\n",
    "img1 = cv.resize(img1, (500,300))\n",
    "img2 = cv.imread(\"resources/image_gray.png\")\n",
    "img2 = cv.resize(img2, (500,300))\n",
    "\n",
    "\n",
    "# stacking same image\n",
    "# 1- Horizontal stack\n",
    "hor_img = np.hstack((img1, img2))\n",
    "\n",
    "# 2- Vertical stack\n",
    "ver_stack = np.vstack((img1, img2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# cv.imshow('Horizontal', hor_img)\n",
    "cv.imshow('Vertical', ver_stack)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18- How to change the perspective of an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"resources/warp.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "#  defining points\n",
    "point1 = np.float32([[78,251], [380,126], [201,467], [504,277]])\n",
    "width = 532\n",
    "height = 594\n",
    "point2 = np.float32([[0,0], [width,0], [0,height], [width, height]])\n",
    "\n",
    "matrix = cv. getPerspectiveTransform(point1, point2)\n",
    "out_img = cv.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "cv.imshow('Original', img)\n",
    "cv.imshow('Transformed', out_img)\n",
    "cv.imwrite('resources/warp_perspective.png', out_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19- Coordinates of an image or video\n",
    "### BGR color codes from an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-1 import libraries\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Step-2 define a function\n",
    "def find_coord(event, x, y, flags,params):  # pramas = parametor\n",
    "    if event == cv.EVENT_LBUTTONDOWN:\n",
    "     # left mouse click\n",
    "     print(x,'', y)\n",
    "     # how to define or print on the same image or window\n",
    "     font = cv.FONT_HERSHEY_PLAIN\n",
    "     cv.putText(img, str(x) + ',' + str(y), (x,y), font,1, (255,0,179), thickness=2)\n",
    "     # show the text on image\n",
    "     cv.imshow('Image', img)\n",
    "     \n",
    "     # for color finding\n",
    "     if event==cv.EVENT_RBUTTONDOWN:\n",
    "         print(x,'', y)\n",
    "         font = cv.FONT_HERSHEY_SIMPLEX\n",
    "         b = img[y,x,0]\n",
    "         g = img[y,x,1]\n",
    "         r = img[y,x,2]\n",
    "         cv.putText(img, str(b) + ',' + str(g) + ',' + str(r), (x,y), font, 1, (255,0,0), 2)\n",
    "         cv.imshow('Image', img)\n",
    "         \n",
    "     \n",
    "# Step-3 final function to read and display\n",
    "if __name__==\"__main__\":\n",
    "    # adding an image\n",
    "    img = cv.imread('resources/warp.jpg', 1)\n",
    "    # display the image\n",
    "    cv.imshow(\"Image\", img)\n",
    "    # setting call back function\n",
    "    cv.setMouseCallback('Image', find_coord)\n",
    "    \n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20- Split your video into frames or image sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "cap = cv.VideoCapture('resources/video1.mkv')\n",
    "\n",
    "frameNr = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv.imwrite(f'resources/frames/frame_{frameNr}.png', frame)\n",
    "    else:\n",
    "        break\n",
    "    frameNr = frameNr+1\n",
    "cap.release()\n",
    "cv.destroyAllWindows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21- How to detect specific colors inside Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signal import CTRL_C_EVENT\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('resources/zaheer.png')\n",
    "\n",
    "# convert in HSV (hue, saturation, value)\n",
    "# hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "# slider\n",
    "def slider():\n",
    "    pass\n",
    "path = \"resources/zaheer.png\"\n",
    "\n",
    "cv.namedWindow('Bars')\n",
    "cv.resizeWindow('Bars', (1100,300))\n",
    "\n",
    "cv.createTrackbar('Hue Min', 'Bars', 0,179,slider)\n",
    "cv.createTrackbar('Hue Max', 'Bars', 179,179,slider)\n",
    "cv.createTrackbar('Sat Min', 'Bars', 0,255,slider)\n",
    "cv.createTrackbar('Sat Max', 'Bars', 255,255,slider)\n",
    "cv.createTrackbar('Val Min', 'Bars', 0,255,slider)\n",
    "cv.createTrackbar('Val Max', 'Bars', 255,255,slider)\n",
    "\n",
    "img = cv.imread(path)\n",
    "hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# hue_min = cv.getTrackbarPos('Hue Min', 'Bars')\n",
    "# print(hue_min)\n",
    "\n",
    "while True:\n",
    "    img = cv.imread(path)\n",
    "    hsv_img = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    hue_min = cv.getTrackbarPos('Hue Min', 'Bars')\n",
    "    hue_max = cv.getTrackbarPos('Hue Max', 'Bars')\n",
    "    sat_min = cv.getTrackbarPos('Sat Min', 'Bars')\n",
    "    sat_max = cv.getTrackbarPos('Sat Max', 'Bars')\n",
    "    val_min = cv.getTrackbarPos('Val Min', 'Bars')\n",
    "    val_max = cv.getTrackbarPos('Val Max', 'Bars')\n",
    "    print(hue_min, hue_max, sat_min, sat_max, val_min, val_max)\n",
    "    \n",
    "    # to see these changes inside an image\n",
    "    lower = np.array([hue_min, sat_min, val_min])\n",
    "    upper = np.array([hue_max, sat_max, val_max])\n",
    "    mask_img = cv.inRange(hsv_img, lower, upper)\n",
    "    out_img = cv.bitwise_and(img, img,mask=mask_img)\n",
    "    \n",
    "    \n",
    "    # cv.imshow('Original', img)\n",
    "    # cv.imshow('HSV', hsv_img)\n",
    "    cv.imshow('Mask', mask_img)\n",
    "    cv.imshow('Final Output', out_img)\n",
    "    if cv.waitKey(1) & 0xff == ord('q'):\n",
    "            break\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22- Face detection in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from cv2 import cvtColor\n",
    "face_cascade = cv.CascadeClassifier('resources/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv.imread(\"resources/zaheer.png\")\n",
    "gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray_img, 1.1, 4)\n",
    "\n",
    "# draw a rectangle\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(img, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "                 \n",
    "cv.imshow('Image', img)\n",
    "cv.imwrite('resources/face.png', img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
